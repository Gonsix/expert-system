{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "count, list and order the frequency of words essential\n",
        "count, list and order the frequency of keywords essential\n",
        "allow user to select reference corpus essential\n",
        "allow user to select statistical formular for keyness\n",
        "display the first 20 words/keywords of each dataset\n",
        "\n",
        "order the known datasets by number of shared words/keywords with questionned dataset\n",
        "display the shared words/keywords in the first 20 words/keywords of each dataset essential\n",
        "identify the most similiar dataset based on the highest number of shared top 20 words/keywords of the questionned dataset\n",
        "identify the least similiar dataset based on the lowest number of shared top 20 words/keywords of the questionned dataset essential\n",
        "suggest to rule out the least similiar dataset essential\n",
        "allow user to confirm or reject ruling out\n",
        "continue to identify the most/least similiar dataset and rule out the least for the top 40, then 60 keywords\n",
        "\n",
        "tag the part-of-speech (POS) of each word essential\n",
        "allow the user to select any word or string and display the word or string in context essential\n",
        "show 6 words before the target and 6 after the target word for each instance of the word in each dataset\n",
        "allow the user to search for POS patterns following the target word, e.g. absolutely + JJ essential\n",
        "count the number of identical POS patterns in each dataset essential\n",
        "order the known datasets by number of identical POS patterns with the questionned dataset\n",
        "identify the most similiar dataset based on the number of identical POS patterns with questionned dataset\n",
        "identify the least similiar dataset based on the number of identical POS patterns with questionned dataset essential\n",
        "suggest ruling out the least similiar dataset essential\n",
        "allow user to confirm or reject ruling out"
      ],
      "metadata": {
        "id": "f-SFBw8vfXfg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKqY6J0pdYTM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df = pd.read_csv(\"preprocessed_enron.csv\")\n",
        "df['body']\n",
        "\n",
        "for i, msg in enumerate(df['body']):\n",
        "    # print(i, msg)\n",
        "\n",
        "    if msg is np.nan:\n",
        "        df = df.drop(i)\n",
        "\n",
        "\n",
        "for i, msg in enumerate(df['body']):\n",
        "    if msg is np.nan:\n",
        "        print(i, msg)\n",
        "\n",
        "df = df.reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ2VAiFXqBRM",
        "outputId": "167aaba2-e817-49a1-b49e-f10c79b5ef6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2854"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vaALdJiudYTX"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "documents = df['body'].tolist()\n",
        "\n",
        "# for i, msg in enumerate(df['body']):\n",
        "#     # print(i, msg)\n",
        "#     if msg is np.nan:\n",
        "#         print(i, msg)\n",
        "\n",
        "#tfidf_vectorizer = TfidfVectorizer()\n",
        "#tfidf_vectors = tfidf_vectorizer.fit_transform(documents) # keyword frequency list\n",
        "tf_vectorizer = CountVectorizer()\n",
        "tf_vectors = tf_vectorizer.fit_transform(documents)         # word frequency list\n",
        "# del tf_vectorizer\n",
        "# del tfidf_vectorizer# データ分割r\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(documents)"
      ],
      "metadata": {
        "id": "3whZTsPBrMtE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YC3Da5ZXdYTb"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mblTowsDdYTg",
        "outputId": "93aed1ca-354a-4617-ff20-07b062776625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['kitchen' 'kkenyan' 'kll' 'klussmann' 'km']\n"
          ]
        }
      ],
      "source": [
        "# 作成された辞書を作る　:トレインデータ・テストデータ両方に対応\n",
        "words=tf_vectorizer.get_feature_names_out()\n",
        "print(words[5020:5025])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNCL7tHudYTh"
      },
      "outputs": [],
      "source": [
        "#tfidf_mat = tfidf_vectors.toarray() # dead every time\n",
        "#del tfidf_vectors\n",
        "tf_mat = tf_vectors.toarray()\n",
        "del tf_vectors\n",
        "df['tf'] = tf_mat.tolist()\n",
        "#df['tfidf'] = tfidf_mat.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 ベクトルを消去 Normalization のため\n",
        "for i, vec in enumerate(df['tf']):\n",
        "    if sum(vec) == 0:\n",
        "        df = df.drop(i)\n",
        "\n",
        "df = df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "ZSGL6Vbkngv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ZcHbe8Fj2y-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalization\n",
        "\n",
        "# we generaly name 'ntf' for normalized term frequency\n",
        "normalized_tf_list = []\n",
        "for row in df['tf']:\n",
        "    num_words = sum(row)\n",
        "    normalized_tf = []\n",
        "    for x in row:\n",
        "        normalized_tf.append(x/num_words)\n",
        "\n",
        "    normalized_tf_list.append(normalized_tf)\n",
        "\n",
        "df['ntf'] = normalized_tf_list"
      ],
      "metadata": {
        "id": "ekr7GC_agOtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "math.log2(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "us0z56Gu4vXb",
        "outputId": "a0fde39b-a84d-4f1d-e708-82f4815ef29f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-177-c71b7acd3ae9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: math domain error"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tf-idf の代わりに利用する keyness を作る\n",
        "\n",
        "ここでは　df['keyness'] を作成し追加したい"
      ],
      "metadata": {
        "id": "TzgePT9IdscE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "# we generaly name 'ntf' for normalized term frequency\n",
        "\n",
        "\n",
        "# First, create the shared normalized tf vector\n",
        "shared_ntf = None # shared ntf of all document\n",
        "\n",
        "matrix = []\n",
        "for row in df['ntf']:\n",
        "    matrix.append(row)\n",
        "\n",
        "np_matrix = np.array(matrix)\n",
        "\n",
        "mean_vector = np_matrix.mean(axis=0)\n",
        "\n",
        "shared_ntf = mean_vector.tolist()\n",
        "\n",
        "\n",
        "\n",
        "def keyness(ntf_vector1, ref_ntf_vector2): # freq_vector1 and freq_vector2 are both already normalized\n",
        "    keyness_vec = []\n",
        "    for i, x in enumerate(ntf_vector1):\n",
        "        if ntf_vector1[i] == 0:\n",
        "            keyness_vec.append(0)\n",
        "        else:\n",
        "            keyness_vec.append(math.log2(ntf_vector1[i]/ref_ntf_vector2[i]))\n",
        "\n",
        "    return keyness_vec\n",
        "\n",
        "\n",
        "keyness_mat = []\n",
        "for ntf_vector in df['ntf']:\n",
        "    keyness_vec = keyness(ntf_vector, shared_ntf)\n",
        "    keyness_mat.append(keyness_vec)\n",
        "\n"
      ],
      "metadata": {
        "id": "d0mwa0wUdruP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['keyness'] = keyness_mat\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "INSZS4YP7NgY",
        "outputId": "68840099-2c1f-4dfd-c4ce-7b8da9202630"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                       author  \\\n",
              "0     chris.stokley@enron.com   \n",
              "1     chris.stokley@enron.com   \n",
              "2     chris.stokley@enron.com   \n",
              "3     chris.stokley@enron.com   \n",
              "4     chris.stokley@enron.com   \n",
              "...                       ...   \n",
              "2649     ben.jacoby@enron.com   \n",
              "2650     ben.jacoby@enron.com   \n",
              "2651     ben.jacoby@enron.com   \n",
              "2652     ben.jacoby@enron.com   \n",
              "2653     ben.jacoby@enron.com   \n",
              "\n",
              "                                                   body  \\\n",
              "0     Please view the summary tab on each worksheet ...   \n",
              "1     Please view the summary tab on each worksheet ...   \n",
              "2     Please view the summary tab on each worksheet ...   \n",
              "3     Please stop by this morning for cake and cooki...   \n",
              "4     Please stop by this morning for cake and cooki...   \n",
              "...                                                 ...   \n",
              "2649  I talked to Bill Butler after this came out. B...   \n",
              "2650  Gentlemen:\\n\\nFurther to our conversation, ple...   \n",
              "2651  I talked to Bill Butler after this came out. B...   \n",
              "2652  Charles:\\n\\nIt was good to catch up with you t...   \n",
              "2653  Charles:\\n\\nIt was good to catch up with you t...   \n",
              "\n",
              "                                                     tf  \\\n",
              "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "...                                                 ...   \n",
              "2649  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2650  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2651  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2652  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2653  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "\n",
              "                                                    ntf  \\\n",
              "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "...                                                 ...   \n",
              "2649  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2650  [0.02040816326530612, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
              "2651  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2652  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "2653  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
              "\n",
              "                                                keyness  \n",
              "0     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "...                                                 ...  \n",
              "2649  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2650  [3.8738423573420007, 0, 0, 0, 0, 0, 0, 0, 0, 0...  \n",
              "2651  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2652  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2653  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "\n",
              "[2654 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-81d126a4-ee83-4be8-9a61-88b9aa909876\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>author</th>\n",
              "      <th>body</th>\n",
              "      <th>tf</th>\n",
              "      <th>ntf</th>\n",
              "      <th>keyness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>chris.stokley@enron.com</td>\n",
              "      <td>Please view the summary tab on each worksheet ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>chris.stokley@enron.com</td>\n",
              "      <td>Please view the summary tab on each worksheet ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>chris.stokley@enron.com</td>\n",
              "      <td>Please view the summary tab on each worksheet ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>chris.stokley@enron.com</td>\n",
              "      <td>Please stop by this morning for cake and cooki...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chris.stokley@enron.com</td>\n",
              "      <td>Please stop by this morning for cake and cooki...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2649</th>\n",
              "      <td>ben.jacoby@enron.com</td>\n",
              "      <td>I talked to Bill Butler after this came out. B...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2650</th>\n",
              "      <td>ben.jacoby@enron.com</td>\n",
              "      <td>Gentlemen:\\n\\nFurther to our conversation, ple...</td>\n",
              "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.02040816326530612, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>[3.8738423573420007, 0, 0, 0, 0, 0, 0, 0, 0, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2651</th>\n",
              "      <td>ben.jacoby@enron.com</td>\n",
              "      <td>I talked to Bill Butler after this came out. B...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2652</th>\n",
              "      <td>ben.jacoby@enron.com</td>\n",
              "      <td>Charles:\\n\\nIt was good to catch up with you t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2653</th>\n",
              "      <td>ben.jacoby@enron.com</td>\n",
              "      <td>Charles:\\n\\nIt was good to catch up with you t...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2654 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-81d126a4-ee83-4be8-9a61-88b9aa909876')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-48aee2e5-ed10-4a90-a116-08b00e0cb987\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-48aee2e5-ed10-4a90-a116-08b00e0cb987')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-48aee2e5-ed10-4a90-a116-08b00e0cb987 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-81d126a4-ee83-4be8-9a61-88b9aa909876 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-81d126a4-ee83-4be8-9a61-88b9aa909876');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 22\n",
        "msg = df['body'][i]\n",
        "max_value = max(keyness_mat[i])\n",
        "max_idx = keyness_mat[i].index(max_value)\n",
        "print(words[max_idx])\n",
        "\n",
        "print(msg)\n",
        "#print(df['author'][i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jlIDOCY5Fvv",
        "outputId": "d8b59944-2c2d-4f16-e786-058b28482389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mechelle\n",
            "Mechelle,\n",
            "            I will let you make the call, MW's or $'s. Look at the spreadsheet  below and give me your thoughts.\n",
            " \n",
            "                                                              Chris\n",
            "              \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saGlZu9odYTi"
      },
      "source": [
        "# データ分割"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-UZnYWEVdYTj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_tfidf_train, X_tfidf_test, Y_tfidf_train, Y_tfidf_test = train_test_split(df['tfidf'],df['author'],test_size=0.2,shuffle=True)\n",
        "X_tf_train, X_tf_test, Y_tf_train, Y_tf_test = train_test_split(df['tf'],df['author'],test_size=0.2,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5lkXXfDdYTl"
      },
      "outputs": [],
      "source": [
        "# How many author?\n",
        "authors = set(Y_tfidf_test)\n",
        "authors_list = [author for author in authors]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aedNBJK4dYTm"
      },
      "source": [
        "# Feature_vectors の作成\n",
        "size: 著者の数\n",
        "\n",
        "Train データから作る"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgdwL7B0dYTn"
      },
      "outputs": [],
      "source": [
        "# df_X = pd.DataFrame(X_tf_train.values.tolist())\n",
        "# df_Y = pd.DataFrame(Y_tf_train.values.tolist())\n",
        "df_concat = pd.concat((X_tfidf_train, Y_tfidf_train.rename('author')), axis=1)\n",
        "\n",
        "reference_vectors = {}\n",
        "for author in authors:\n",
        "\n",
        "    df_author = df_concat.groupby('author').get_group(author)\n",
        "\n",
        "    matrix = []\n",
        "    for row in df_author['tfidf']:\n",
        "        matrix.append(row)\n",
        "\n",
        "    np_matrix = np.array(matrix)\n",
        "\n",
        "    mean_vector = np_matrix.mean(axis=0)\n",
        "    reference_vectors[author] = mean_vector.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRE3PFpedYTo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NubkriNNdYTp",
        "outputId": "41ea8141-48b3-4ec9-8a11-4c368011cfe1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'andy.zipper@enron.com',\n",
              " 'ben.jacoby@enron.com',\n",
              " 'chris.stokley@enron.com',\n",
              " 'hunter.shively@enron.com',\n",
              " 'j..kean@enron.com',\n",
              " 'v.weldon@enron.com'}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c9DcF4GdYTq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiWlQAk5dYTr"
      },
      "source": [
        "# Problem\n",
        "\n",
        "Tf-idf でも　the や　to などの一般的な単語が強調されてしまった。emails のデータセットの場合だと、全ての文章に含まれているわけではないので抑制作用が弱くなる\n",
        "\n",
        "# Solution\n",
        "\n",
        "nltk の　stop_words から commonly used words を　取得し、それらを省いた中でのtop20 を出す"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6g6FXopdYTu",
        "outputId": "1b26246d-472e-468f-b164-bfb0b1257c33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRL-ew4LdYTv",
        "outputId": "c9eeeb2f-1ea5-4bb9-e67b-d2a3ac107e06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'andy.zipper@enron.com',\n",
              " 'ben.jacoby@enron.com',\n",
              " 'chris.stokley@enron.com',\n",
              " 'hunter.shively@enron.com',\n",
              " 'j..kean@enron.com',\n",
              " 'v.weldon@enron.com'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "authors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1xmL_xLdYTy",
        "outputId": "4bfdd470-915e-4a31-c2f7-a1f168f57080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "179"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "print(stop_words)\n",
        "len(stop_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byj_PcU4dYTz"
      },
      "outputs": [],
      "source": [
        "# start からend までのwordの配列を返す\n",
        "def extract_features_words(freq_vector, words,stop_words, start=0, end=20):\n",
        "\n",
        "    setX = set(freq_vector) # 最大値を取り出すため set を作成\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    result = []\n",
        "\n",
        "    while count<end:\n",
        "        max_value = max(setX)\n",
        "        max_index = freq_vector.index(max_value)\n",
        "        max_word = words[max_index]\n",
        "\n",
        "        setX.remove(max_value)\n",
        "\n",
        "        if max_word not in stop_words:\n",
        "            if count>= start:\n",
        "                result.append(max_word)\n",
        "            count+=1\n",
        "        # count += 1\n",
        "\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sUvSp9pdYT1"
      },
      "outputs": [],
      "source": [
        "# start からend までのword IDの配列を返す\n",
        "def extract_features(freq_vector, words,stop_words, start=0, end=20):\n",
        "\n",
        "    setX = set(freq_vector) # 最大値を取り出すため set を作成\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    result = []\n",
        "\n",
        "    while count<end:\n",
        "        max_value = max(setX)\n",
        "        max_index = freq_vector.index(max_value)\n",
        "        max_word = words[max_index]\n",
        "\n",
        "        setX.remove(max_value)\n",
        "\n",
        "        if max_word not in stop_words:\n",
        "            if count>= start:\n",
        "                result.append(max_index)\n",
        "            count+=1\n",
        "        # count += 1\n",
        "\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3XEgqOTdYT3",
        "outputId": "312023bc-f03e-4bf0-a82c-8beca20c43e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['charlie', 'thanks', 'com', 'http', 'enron', '20', 'weldon', 'know', 'good', 'www', 'let', 'asp', 'gas', 'one', 'got', 'thank', 'need', 'sure', 'would', 'lunch', 'link', 'call', 'ect', 'fuel', 'data', 'time', 'go', 'may', 'get', 'likely', '2001', '7229', '01', 'year', 'going', 'corp', 'weather', 'want', 'sounds', 'per', 'framework', 'bought', 'dev', '2000', 'based', '345', 'default', 'think', 'stagecoach', 'today', 'charles', 'html', 'last', 'info', 'could', 'new', 'news', 'previous', 'come', '713', 'research', 'pretty', 'energy', 'note', 'saw', 'melissa', 'next', 'still', 'updated', 'yahoo', 'looking', 'gov', 'bid', 'money', 'curves', 'htm', '22', 'ene', 'gasfundy', 'work', 'check', 'vanadium', 'great', 'capacity', 'subject', 'please', 'much', 'attend', 'see', 'really', 'less', 'week', 'oil', 'years', 'wanted', 'like', 'niagara', 'prices', 'buy', 'show', 'yesterday', 'sell', 'also', 'company', 'able', 'hours', 'doug', 'night', 'cold', 'cc', 'business', 'tonight', 'hurricane', 'assistance', '103', 'class', 'long', 'texas', 'well', '10', 'quotes', 'biz', 'spec', 'though', 'market', 'professional', 'sample', 'forward', 'vacation', '300', 'hou', 'weekend', 'rc', 'dynegy', 'maybe', 'irony', 'attached', 'saturday', 'mmbtu', 'quote', 'january', 'take', 'system', 'exactly', 'appreciate', 'dr', 'yeah', 'eberle', 'love', 'files']\n"
          ]
        }
      ],
      "source": [
        "vec = reference_vectors['v.weldon@enron.com']\n",
        "top_words = extract_features_words(vec, words=words, stop_words=stop_words,  start=0, end=150)\n",
        "print(top_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSjVWTSmdYT4"
      },
      "source": [
        "# ReferenceVectors 完成\n",
        "\n",
        "## next\n",
        "\n",
        "# predict() 関数の作成"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similarity(feature_vector1,feature_vector2):\n",
        "    return len(set(feature_vector1) & set(feature_vector2))\n",
        "\n"
      ],
      "metadata": {
        "id": "xWhTAjQYkwOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict(questioned_vector,reference_vectors):\n",
        "    start = 0\n",
        "    end = 20\n",
        "    suspected = [author for author in authors]\n",
        "    similarityWithQ = {}\n",
        "    while(len(suspected) > 1):\n",
        "        Q_features = extract_features(questioned_vector, words,start, end)\n",
        "        for author, reference_vector in reference_vectors.items():\n",
        "            feature_vector = extract_features(reference_vector, words, start, end)\n",
        "            score = get_similarity(reference_vector,Q_features)\n",
        "            similarityWithQ[author]=score\n",
        "        print(f'{min(similarityWithQ, key=similarityWithQ.get)} is minimum')\n",
        "\n",
        "        end += 20\n"
      ],
      "metadata": {
        "id": "BBTAic9Mdytb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IoM1rGcdYT5"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q3atvZGPkAP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "t7ltZakCdYT6",
        "outputId": "e4c0eddf-839e-4973-cf02-9d55ae8bb34d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-35-80908a6be27c>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ],
      "source": [
        "# def predict(questioned_vector, reference_vectors):\n",
        "#     suspected = [author for author in authors]\n",
        "\n",
        "#     comparedSize = 20\n",
        "#     while(len(suspected) > 1):\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wee-RGzbdYT7"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o3thPLxAdYT9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6PHDHBmdYT-"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsTpIbg_dYT_"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "expsystem",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}