{"cells":[{"cell_type":"markdown","metadata":{"id":"p9vEDloTOkQ1"},"source":["# 3.allow user to select reference corpus\n","\n","#Feature3"]},{"cell_type":"code","execution_count":317,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2652,"status":"ok","timestamp":1689907909136,"user":{"displayName":"米田武士","userId":"14881788265874075884"},"user_tz":-540},"id":"ln46tEDTOQt6","outputId":"b415042c-13c9-4b7b-827e-83324cf07c82"},"outputs":[{"name":"stdout","output_type":"stream","text":["SUCCESS: You chose: 2 Enron corpus\n"]}],"source":["dataset1 = \"Brown corpus\"\n","dataset2 = \"Enron corpus\"\n","while 1:\n","    selected_dataset = input(f'Select Courpus you want to use: \\n 1: {dataset1} 2: {dataset2}\\n')\n","    selected_dataset = int(selected_dataset)\n","    if(selected_dataset == 1 or selected_dataset ==2):\n","        exec_command = \"print(f'SUCCESS: You chose: \" + str(selected_dataset) + \" \" + \"{dataset\" + str(selected_dataset) + \"}')\"\n","        exec(exec_command)\n","        break\n","    print('Please input decimal number\\n')\n","    try:\n","        selected_dataset = int(selected_dataset)\n","    except:\n","        print('Please input decimal number\\n')\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Remove NaN and Change Enron Documents into one Document"]},{"cell_type":"code","execution_count":318,"metadata":{"id":"TlXI0jWwYSVb"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","pd.set_option('display.max_rows', None)\n","pd.set_option('display.max_columns', None)\n","def rmNan(df):\n","    #remove nan\n","    for i, msg in enumerate(df['body']):\n","        # print(i, msg)\n","        if msg is np.nan:\n","            df = df.drop(i)\n","    for i, msg in enumerate(df['body']):\n","        if msg is np.nan:\n","            print(i, msg) \n","\n","    #merge documents into one\n","    str_all_document=''\n","    for index, record in df.iterrows():\n","        str_all_document = str_all_document + str(record[1])\n","    del df\n","    \n","    return pd.DataFrame({\"author\":[\"ENRON DATASET\"],\n","                        \"body\": [str_all_document]})\n","            "]},{"cell_type":"markdown","metadata":{"id":"zOvUoP9sRtVm"},"source":["## Make DataFrame, Q, K1, K2, and Enron or Brown Datasets"]},{"cell_type":"code","execution_count":319,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1689908970311,"user":{"displayName":"米田武士","userId":"14881788265874075884"},"user_tz":-540},"id":"lKqY6J0pdYTM"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","\n","def makeDataset(datasetnum = 0):\n","    if(datasetnum == 2):\n","        df = pd.read_csv(\"preprocessed_enron.csv\")\n","        df = rmNan(df)\n","    elif(datasetnum== 1):\n","        f = open('Brown_ca_ca01.txt', 'r')\n","        data = f.read()\n","        f.close()\n","        df = pd.DataFrame({\"author\":[\"BROWN DATASET\"],\n","                          \"body\": [data]})\n","    return df.reset_index(drop=True)"]},{"cell_type":"code","execution_count":320,"metadata":{},"outputs":[],"source":["#Make df_Q dataset \n","f = open('Q_dataset.txt', 'r')\n","data = f.read()\n","f.close()\n","df_Q = pd.DataFrame({\"author\":[\"Q DATASET\"],\n","                    \"body\": [data]})\n","                    "]},{"cell_type":"code","execution_count":321,"metadata":{},"outputs":[],"source":["#Make df_K1 dataset \n","f = open('K1_dataset.txt', 'r')\n","data = f.read()\n","f.close()\n","df_K1 = pd.DataFrame({\"author\":[\"K1 DATASET\"],\n","                    \"body\": [data]})\n"]},{"cell_type":"code","execution_count":322,"metadata":{},"outputs":[],"source":["#Make df_K2 dataset \n","f = open('K2_dataset.txt', 'r')\n","data = f.read()\n","f.close()\n","df_K2 = pd.DataFrame({\"author\":[\"K2 DATASET\"],\n","                    \"body\": [data]})"]},{"cell_type":"code","execution_count":323,"metadata":{},"outputs":[],"source":["#Make df_ref dataset \n","df_ref = makeDataset(selected_dataset)"]},{"cell_type":"code","execution_count":324,"metadata":{},"outputs":[],"source":["df = pd.concat([df_Q,df_K1, df_K2, df_ref])\n","df = df.reset_index(drop=True)\n","del df_Q, df_K1,df_K2,df_ref"]},{"cell_type":"code","execution_count":325,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author</th>\n","      <th>body</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Q DATASET</td>\n","      <td>\\n\\nHowever, there are frequent situations whe...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>K1 DATASET</td>\n","      <td>Download\\n\\nSource\\n\\nPDF\\nActions\\n   Copy Pr...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>K2 DATASET</td>\n","      <td>\\n\\nWith the rapid growth of the information c...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ENRON DATASET</td>\n","      <td>Please view the summary tab on each worksheet ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          author                                               body\n","0      Q DATASET  \\n\\nHowever, there are frequent situations whe...\n","1     K1 DATASET  Download\\n\\nSource\\n\\nPDF\\nActions\\n   Copy Pr...\n","2     K2 DATASET  \\n\\nWith the rapid growth of the information c...\n","3  ENRON DATASET  Please view the summary tab on each worksheet ..."]},"execution_count":325,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{},"source":["# 1. count, list and order the frequency of words \n","\n","#Feature1"]},{"cell_type":"code","execution_count":326,"metadata":{"id":"vaALdJiudYTX"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_extraction.text import CountVectorizer\n","def tokenizeFunc(documents):\n","    # documents = df['body'].tolist()\n","    tf_vectorizer = CountVectorizer()\n","    tf_vectors = tf_vectorizer.fit_transform(documents)         # word frequency list\n","    return tf_vectors, tf_vectorizer\n","# for i, msg in enumerate(df['body']):\n","#     # print(i, msg)\n","#     if msg is np.nan:\n","#         print(i, msg)\n","#tfidf_vectorizer = TfidfVectorizer()\n","#tfidf_vectors = tfidf_vectorizer.fit_transform(documents) # keyword frequency list\n","# tf_vectorizer = CountVectorizer()\n","# tf_vectors = tf_vectorizer.fit_transform(documents)         # word frequency list\n","# del tf_vectorizer\n","# del tfidf_vectorizer# データ分割r"]},{"cell_type":"markdown","metadata":{},"source":["### Make All datasets a list and make tf vector and tf vectrizer"]},{"cell_type":"code","execution_count":327,"metadata":{},"outputs":[],"source":["documents=[\n","    df['body'][0], #df_Q['body'][0],\n","    df['body'][1], #df_K1['body'][0],\n","    df['body'][2], #df_K2['body'][0],\n","    df['body'][3], #df_ref['body'][0],]\n","]\n","tf_vectors, tf_vectorizer = tokenizeFunc(documents)\n"]},{"cell_type":"code","execution_count":328,"metadata":{},"outputs":[],"source":["#[remove]Dataframeや単語リストが一つのDFで十分な場合削除　7/25日米田\n","\n","# tf_vectors_Q, tf_vectorizer_Q = tokenizeFunc(df_Q)\n","# tf_vectors_K1, tf_vectorizer_K1 = tokenizeFunc(df_K1)\n","# tf_vectors_K2, tf_vectorizer_K2 = tokenizeFunc(df_K2)\n","# tf_vectors_ref, tf_vectorizer_ref = tokenizeFunc(df_ref)\n","\n","# words_Q=tf_vectorizer_Q.get_feature_names_out()\n","# words_K1=tf_vectorizer_K1.get_feature_names_out()\n","# words_K2=tf_vectorizer_K2.get_feature_names_out()\n","# words_K3=tf_vectorizer_ref.get_feature_names_out()"]},{"cell_type":"markdown","metadata":{},"source":["## Make a words dictionary in all documents "]},{"cell_type":"code","execution_count":329,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":474,"status":"ok","timestamp":1689127987186,"user":{"displayName":"米田武士","userId":"14881788265874075884"},"user_tz":-540},"id":"mblTowsDdYTg","outputId":"d0e28c64-bf6a-46f4-f4b3-930bed4f76a8"},"outputs":[],"source":["# 作成された辞書を作る　:トレインデータ・テストデータ両方に対応\n","words=tf_vectorizer.get_feature_names_out()"]},{"cell_type":"markdown","metadata":{},"source":["## Make the Words frequency matrix "]},{"cell_type":"markdown","metadata":{},"source":["### This Matrix's row indices ared corresponding with a document in the "]},{"cell_type":"code","execution_count":330,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author</th>\n","      <th>body</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Q DATASET</td>\n","      <td>\\n\\nHowever, there are frequent situations whe...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>K1 DATASET</td>\n","      <td>Download\\n\\nSource\\n\\nPDF\\nActions\\n   Copy Pr...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>K2 DATASET</td>\n","      <td>\\n\\nWith the rapid growth of the information c...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ENRON DATASET</td>\n","      <td>Please view the summary tab on each worksheet ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          author                                               body\n","0      Q DATASET  \\n\\nHowever, there are frequent situations whe...\n","1     K1 DATASET  Download\\n\\nSource\\n\\nPDF\\nActions\\n   Copy Pr...\n","2     K2 DATASET  \\n\\nWith the rapid growth of the information c...\n","3  ENRON DATASET  Please view the summary tab on each worksheet ..."]},"execution_count":330,"metadata":{},"output_type":"execute_result"}],"source":["#First row: dataset Q\n","#Second row: dataset K1\n","#Third row: dataset k2\n","#Fourth row: dataset ref\n","df"]},{"cell_type":"markdown","metadata":{},"source":["### This Matrix's col indices are corresponding with a word in the above document"]},{"cell_type":"code","execution_count":331,"metadata":{},"outputs":[{"data":{"text/plain":["array(['00', '000', '000f749c00763c4c3b9aca0044810ab2', ..., 'zoning',\n","       'µm', 'μm'], dtype=object)"]},"execution_count":331,"metadata":{},"output_type":"execute_result"}],"source":["words"]},{"cell_type":"markdown","metadata":{},"source":["## Insert Words Frequemcy Vector into 'tf' Column in DF for Each Dataset"]},{"cell_type":"code","execution_count":332,"metadata":{},"outputs":[],"source":["tf_mat = tf_vectors.toarray()\n","del tf_vectors\n","df['tf'] = tf_mat.tolist()"]},{"cell_type":"code","execution_count":333,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author</th>\n","      <th>body</th>\n","      <th>tf</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Q DATASET</td>\n","      <td>\\n\\nHowever, there are frequent situations whe...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>K1 DATASET</td>\n","      <td>Download\\n\\nSource\\n\\nPDF\\nActions\\n   Copy Pr...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>K2 DATASET</td>\n","      <td>\\n\\nWith the rapid growth of the information c...</td>\n","      <td>[0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ENRON DATASET</td>\n","      <td>Please view the summary tab on each worksheet ...</td>\n","      <td>[199, 73, 1, 2, 1, 0, 4, 1, 3, 280, 8, 3, 3, 1...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          author                                               body  \\\n","0      Q DATASET  \\n\\nHowever, there are frequent situations whe...   \n","1     K1 DATASET  Download\\n\\nSource\\n\\nPDF\\nActions\\n   Copy Pr...   \n","2     K2 DATASET  \\n\\nWith the rapid growth of the information c...   \n","3  ENRON DATASET  Please view the summary tab on each worksheet ...   \n","\n","                                                  tf  \n","0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","2  [0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...  \n","3  [199, 73, 1, 2, 1, 0, 4, 1, 3, 280, 8, 3, 3, 1...  "]},"execution_count":333,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":334,"metadata":{"id":"WNCL7tHudYTh"},"outputs":[],"source":["#[remove]ここの記述で必要な部分は上記に記述。そのた不要であれば削除\n","\n","#tfidf_mat = tfidf_vectors.toarray() # dead every time\n","#del tfidf_vectors\n","# tf_mat = tf_vectors.toarray()\n","# del tf_vectors\n","# df['tf'] = tf_mat.tolist()\n","#df['tfidf'] = tfidf_mat.tolist()"]},{"cell_type":"code","execution_count":335,"metadata":{"id":"ZSGL6Vbkngv5"},"outputs":[],"source":["#[remove]今回はからのデータセットがそんざいしないため。確認後削除\n","\n","# 0 ベクトルを消去 Normalization のため\n","# for i, vec in enumerate(df['tf']):\n","#     if sum(vec) == 0:\n","#         df = df.drop(i)\n","\n","# df = df.reset_index(drop=True)"]},{"cell_type":"markdown","metadata":{},"source":["# 5. display the first 20 words of each dataset \n","\n","#Feature5"]},{"cell_type":"code","execution_count":336,"metadata":{},"outputs":[],"source":["def dispAndMakeWordFreq(df, words, author = 0):\n","    data = df.loc[author]\n","    freq = data['tf']\n","    wf = pd.DataFrame({'words': words, 'frequency': freq})\n","    wordli = []\n","    freqli =[]\n","    for key, data in wf.iterrows():\n","        if(int(data[1]) != 0):\n","            wordli.append(data[0])\n","            freqli.append(data[1])\n","        \n","    return pd.DataFrame({'words': wordli, 'frequency': freqli})\n","    \n"]},{"cell_type":"markdown","metadata":{},"source":["## Words Frequency of Dataset Q"]},{"cell_type":"code","execution_count":337,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>frequency</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>186</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>of</td>\n","      <td>89</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>and</td>\n","      <td>74</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>to</td>\n","      <td>70</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>for</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>in</td>\n","      <td>54</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>be</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>or</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>planning</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>is</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>are</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>as</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>time</td>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>location</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>user</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>based</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>that</td>\n","      <td>20</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>system</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>such</td>\n","      <td>18</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>figure</td>\n","      <td>18</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       words  frequency\n","0        the        186\n","1         of         89\n","2        and         74\n","3         to         70\n","4        for         55\n","5         in         54\n","6         be         45\n","7         or         40\n","8   planning         33\n","9         is         31\n","10       are         31\n","11        as         28\n","12      time         28\n","13  location         27\n","14      user         26\n","15     based         20\n","16      that         20\n","17    system         19\n","18      such         18\n","19    figure         18"]},"execution_count":337,"metadata":{},"output_type":"execute_result"}],"source":["wf_list_Q = dispAndMakeWordFreq(df,words, author = 0)\n","\n","wf_list_Q = wf_list_Q.sort_values('frequency', ascending=False)\n","wf_list_Q = wf_list_Q.reset_index(drop=True)\n","wf_list_Q.head(20)"]},{"cell_type":"markdown","metadata":{},"source":["## Words Frequency of Dataset K1"]},{"cell_type":"code","execution_count":338,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>frequency</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>78</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>of</td>\n","      <td>66</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>and</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>in</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>to</td>\n","      <td>39</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>as</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>music</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>for</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>is</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>be</td>\n","      <td>16</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>on</td>\n","      <td>15</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>tchaikovsky</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>by</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>that</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>can</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>not</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>between</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>such</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>similarity</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>models</td>\n","      <td>10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          words  frequency\n","0           the         78\n","1            of         66\n","2           and         50\n","3            in         42\n","4            to         39\n","5            as         32\n","6         music         25\n","7           for         17\n","8            is         17\n","9            be         16\n","10           on         15\n","11  tchaikovsky         13\n","12           by         13\n","13         that         12\n","14          can         12\n","15          not         11\n","16      between         11\n","17         such         11\n","18   similarity         11\n","19       models         10"]},"execution_count":338,"metadata":{},"output_type":"execute_result"}],"source":["wf_list_K1 = dispAndMakeWordFreq(df,words, author = 1)\n","wf_list_K1 = wf_list_K1.sort_values('frequency', ascending=False)\n","wf_list_K1 = wf_list_K1.reset_index(drop=True)\n","wf_list_K1.head(20)"]},{"cell_type":"markdown","metadata":{},"source":["## Words Frequency of Dataset K2"]},{"cell_type":"code","execution_count":339,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>frequency</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>383</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>of</td>\n","      <td>161</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>to</td>\n","      <td>128</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>and</td>\n","      <td>121</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>in</td>\n","      <td>119</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>is</td>\n","      <td>91</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>high</td>\n","      <td>76</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>eo</td>\n","      <td>56</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>with</td>\n","      <td>56</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>for</td>\n","      <td>55</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>temperature</td>\n","      <td>53</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>at</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>gbit</td>\n","      <td>46</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>modulator</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>device</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>are</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>sph</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>as</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>polymer</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>up</td>\n","      <td>29</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          words  frequency\n","0           the        383\n","1            of        161\n","2            to        128\n","3           and        121\n","4            in        119\n","5            is         91\n","6          high         76\n","7            eo         56\n","8          with         56\n","9           for         55\n","10  temperature         53\n","11           at         50\n","12         gbit         46\n","13    modulator         45\n","14       device         38\n","15          are         37\n","16          sph         36\n","17           as         36\n","18      polymer         31\n","19           up         29"]},"execution_count":339,"metadata":{},"output_type":"execute_result"}],"source":["wf_list_K2 = dispAndMakeWordFreq(df,words, author = 2)\n","\n","wf_list_K2 = wf_list_K2.sort_values('frequency', ascending=False)\n","wf_list_K2 = wf_list_K2.reset_index(drop=True)\n","wf_list_K2.head(20)"]},{"cell_type":"markdown","metadata":{},"source":["## Words Frequency of Dataset ref"]},{"cell_type":"code","execution_count":340,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>frequency</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>7050</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>to</td>\n","      <td>5262</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>folder</td>\n","      <td>4149</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>synchronizing</td>\n","      <td>4024</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>and</td>\n","      <td>3127</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>enron</td>\n","      <td>2866</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>of</td>\n","      <td>2685</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>ect</td>\n","      <td>2454</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>in</td>\n","      <td>2132</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>you</td>\n","      <td>2097</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>is</td>\n","      <td>1930</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>we</td>\n","      <td>1781</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>for</td>\n","      <td>1702</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>that</td>\n","      <td>1690</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>on</td>\n","      <td>1663</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>20</td>\n","      <td>1581</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>this</td>\n","      <td>1516</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>have</td>\n","      <td>1226</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>hou</td>\n","      <td>1205</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>with</td>\n","      <td>1175</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            words  frequency\n","0             the       7050\n","1              to       5262\n","2          folder       4149\n","3   synchronizing       4024\n","4             and       3127\n","5           enron       2866\n","6              of       2685\n","7             ect       2454\n","8              in       2132\n","9             you       2097\n","10             is       1930\n","11             we       1781\n","12            for       1702\n","13           that       1690\n","14             on       1663\n","15             20       1581\n","16           this       1516\n","17           have       1226\n","18            hou       1205\n","19           with       1175"]},"execution_count":340,"metadata":{},"output_type":"execute_result"}],"source":["wf_list_ref = dispAndMakeWordFreq(df,words, author = 3)\n","wf_list_ref = wf_list_ref.sort_values('frequency', ascending=False)\n","wf_list_ref = wf_list_ref.reset_index(drop=True)\n","wf_list_ref.head(20)"]},{"cell_type":"markdown","metadata":{},"source":["## count, list and order the frequency of keywords\n","#Feature2"]},{"cell_type":"markdown","metadata":{},"source":["## Normalization of Word Frequencies to All Datasets and Add them into DF"]},{"cell_type":"code","execution_count":341,"metadata":{},"outputs":[],"source":["# we generaly name 'ntf' for normalized term frequency\n","normalized_tf_list = []\n","for row in df['tf']:\n","    num_words = sum(row)\n","    normalized_tf = []\n","    for x in row:\n","        normalized_tf.append(x/num_words)\n","    normalized_tf_list.append(normalized_tf)\n","\n","df['ntf'] = normalized_tf_list"]},{"cell_type":"markdown","metadata":{},"source":["#Tf-idf の代わりに利用する keyness を作る\n","\n","ここでは　df['keyness'] を作成し追加したい"]},{"cell_type":"code","execution_count":342,"metadata":{},"outputs":[],"source":["import math\n","# we generaly name 'ntf' for normalized term frequency\n","# First, create the shared normalized tf vector\n","# shared_ntf = None # shared ntf of all document\n","# matrix = []\n","# for row in df['ntf']:\n","#     matrix.append(row)\n","# np_matrix = np.array(matrix)\n","# mean_vector = np_matrix.mean(axis=0)\n","# shared_ntf = mean_vector.tolist()\n","\n","def keyness(ntf_vector1, ref_ntf_vector2): # freq_vector1 and freq_vector2 are both already normalized\n","    keyness_vec = []\n","    for i, x in enumerate(ntf_vector1):\n","        if ntf_vector1[i] == 0 or ref_ntf_vector2[i] == 0:\n","            keyness_vec.append(0)\n","        else:\n","            keyness_vec.append(math.log2(ntf_vector1[i]/ref_ntf_vector2[i]))\n","\n","    return keyness_vec\n","\n","\n","keyness_mat = []\n","for ntf_vector in df['ntf']:\n","    ntf_ref = df['ntf'][3]\n","    keyness_vec = keyness(ntf_vector, ntf_ref)\n","    keyness_mat.append(keyness_vec)\n","\n","# keyness を　Dataframe に追加\n","df['keyness'] = keyness_mat"]},{"cell_type":"code","execution_count":343,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author</th>\n","      <th>body</th>\n","      <th>tf</th>\n","      <th>ntf</th>\n","      <th>keyness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Q DATASET</td>\n","      <td>\\n\\nHowever, there are frequent situations whe...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>K1 DATASET</td>\n","      <td>Download\\n\\nSource\\n\\nPDF\\nActions\\n   Copy Pr...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>K2 DATASET</td>\n","      <td>\\n\\nWith the rapid growth of the information c...</td>\n","      <td>[0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...</td>\n","      <td>[0.0, 0.0004100041000410004, 0.0, 0.0, 0.0, 0....</td>\n","      <td>[0, 0.08323982788213213, 0, 0, 0, 0, 0, 0, 0, ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ENRON DATASET</td>\n","      <td>Please view the summary tab on each worksheet ...</td>\n","      <td>[199, 73, 1, 2, 1, 0, 4, 1, 3, 280, 8, 3, 3, 1...</td>\n","      <td>[0.0010550200930962454, 0.00038701742108555734...</td>\n","      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0....</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          author                                               body  \\\n","0      Q DATASET  \\n\\nHowever, there are frequent situations whe...   \n","1     K1 DATASET  Download\\n\\nSource\\n\\nPDF\\nActions\\n   Copy Pr...   \n","2     K2 DATASET  \\n\\nWith the rapid growth of the information c...   \n","3  ENRON DATASET  Please view the summary tab on each worksheet ...   \n","\n","                                                  tf  \\\n","0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n","2  [0, 2, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, ...   \n","3  [199, 73, 1, 2, 1, 0, 4, 1, 3, 280, 8, 3, 3, 1...   \n","\n","                                                 ntf  \\\n","0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n","1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n","2  [0.0, 0.0004100041000410004, 0.0, 0.0, 0.0, 0....   \n","3  [0.0010550200930962454, 0.00038701742108555734...   \n","\n","                                             keyness  \n","0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n","2  [0, 0.08323982788213213, 0, 0, 0, 0, 0, 0, 0, ...  \n","3  [0.0, 0.0, 0.0, 0.0, 0.0, 0, 0.0, 0.0, 0.0, 0....  "]},"execution_count":343,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{},"source":["# Display the first 20 keywords of each dataset "]},{"cell_type":"code","execution_count":344,"metadata":{},"outputs":[],"source":["def dispAndMakeKeyWordList(df, words, author = 0):\n","    data = df.loc[author]\n","    keyness = data['keyness']\n","    wf = pd.DataFrame({'words': words, 'keyness': keyness})\n","    wordli = []\n","    freqli =[]\n","    for key, data in wf.iterrows():\n","        if(int(data[1]) != 0):\n","            wordli.append(data[0])\n","            freqli.append(data[1])\n","        \n","    return pd.DataFrame({'words': wordli, 'keyness': freqli})"]},{"cell_type":"markdown","metadata":{},"source":["## Keyword of Dataset Q"]},{"cell_type":"code","execution_count":345,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>keyness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>solutions</td>\n","      <td>8.625782</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cloud</td>\n","      <td>8.362747</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>notification</td>\n","      <td>8.362747</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>smart</td>\n","      <td>8.040819</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>configured</td>\n","      <td>8.040819</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>domain</td>\n","      <td>8.040819</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>situations</td>\n","      <td>8.040819</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>advance</td>\n","      <td>7.848174</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>conditions</td>\n","      <td>7.625782</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>implemented</td>\n","      <td>7.625782</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>stage</td>\n","      <td>7.625782</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>proactive</td>\n","      <td>7.625782</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>connected</td>\n","      <td>7.625782</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>frame</td>\n","      <td>7.362747</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>conferences</td>\n","      <td>7.040819</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>linked</td>\n","      <td>7.040819</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>briefly</td>\n","      <td>7.040819</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>component</td>\n","      <td>7.040819</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>overcome</td>\n","      <td>7.040819</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>combination</td>\n","      <td>7.040819</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["           words   keyness\n","0      solutions  8.625782\n","1          cloud  8.362747\n","2   notification  8.362747\n","3          smart  8.040819\n","4     configured  8.040819\n","5         domain  8.040819\n","6     situations  8.040819\n","7        advance  7.848174\n","8     conditions  7.625782\n","9    implemented  7.625782\n","10         stage  7.625782\n","11     proactive  7.625782\n","12     connected  7.625782\n","13         frame  7.362747\n","14   conferences  7.040819\n","15        linked  7.040819\n","16       briefly  7.040819\n","17     component  7.040819\n","18      overcome  7.040819\n","19   combination  7.040819"]},"execution_count":345,"metadata":{},"output_type":"execute_result"}],"source":["keyword_list_Q = dispAndMakeKeyWordList(df,words, author = 0)\n","\n","keyword_list_Q = keyword_list_Q.sort_values('keyness',ascending=False)\n","keyword_list_Q = keyword_list_Q.reset_index(drop=True)\n","keyword_list_Q.head(20)"]},{"cell_type":"markdown","metadata":{},"source":["## Keyword of Dataset K1"]},{"cell_type":"code","execution_count":346,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>keyness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>models</td>\n","      <td>9.259289</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>cope</td>\n","      <td>8.937361</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>mostly</td>\n","      <td>8.522323</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>children</td>\n","      <td>8.107286</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>relationships</td>\n","      <td>7.937361</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>succession</td>\n","      <td>7.937361</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>machine</td>\n","      <td>7.937361</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>art</td>\n","      <td>7.937361</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>insights</td>\n","      <td>7.522323</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>considered</td>\n","      <td>7.522323</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>representation</td>\n","      <td>7.259289</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>figure</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>download</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>desire</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>connected</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>designed</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>preparation</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>standing</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>enhance</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>image</td>\n","      <td>6.937361</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             words   keyness\n","0           models  9.259289\n","1             cope  8.937361\n","2           mostly  8.522323\n","3         children  8.107286\n","4    relationships  7.937361\n","5       succession  7.937361\n","6          machine  7.937361\n","7              art  7.937361\n","8         insights  7.522323\n","9       considered  7.522323\n","10  representation  7.259289\n","11          figure  6.937361\n","12        download  6.937361\n","13          desire  6.937361\n","14       connected  6.937361\n","15        designed  6.937361\n","16     preparation  6.937361\n","17        standing  6.937361\n","18         enhance  6.937361\n","19           image  6.937361"]},"execution_count":346,"metadata":{},"output_type":"execute_result"}],"source":["keyword_list_K1 = dispAndMakeKeyWordList(df,words, author = 1)\n","\n","keyword_list_K1 = keyword_list_K1.sort_values('keyness',ascending=False)\n","keyword_list_K1 = keyword_list_K1.reset_index(drop=True)\n","keyword_list_K1.head(20)"]},{"cell_type":"markdown","metadata":{},"source":["## Keyword of Dataset K2"]},{"cell_type":"code","execution_count":347,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>keyness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>temperature</td>\n","      <td>11.000985</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>device</td>\n","      <td>9.520992</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>observed</td>\n","      <td>8.594992</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>measured</td>\n","      <td>8.273064</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>efficiency</td>\n","      <td>8.179955</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>ber</td>\n","      <td>8.080419</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>strip</td>\n","      <td>8.080419</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>signals</td>\n","      <td>8.080419</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>db</td>\n","      <td>7.732496</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>reliable</td>\n","      <td>7.594992</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>electrical</td>\n","      <td>7.594992</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>driver</td>\n","      <td>7.594992</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>voltage</td>\n","      <td>7.388542</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>stability</td>\n","      <td>7.273064</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>gsa</td>\n","      <td>7.273064</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>burn</td>\n","      <td>7.080419</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>factor</td>\n","      <td>7.080419</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>driving</td>\n","      <td>6.858027</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>extraordinary</td>\n","      <td>6.858027</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>onto</td>\n","      <td>6.858027</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["            words    keyness\n","0     temperature  11.000985\n","1          device   9.520992\n","2        observed   8.594992\n","3        measured   8.273064\n","4      efficiency   8.179955\n","5             ber   8.080419\n","6           strip   8.080419\n","7         signals   8.080419\n","8              db   7.732496\n","9        reliable   7.594992\n","10     electrical   7.594992\n","11         driver   7.594992\n","12        voltage   7.388542\n","13      stability   7.273064\n","14            gsa   7.273064\n","15           burn   7.080419\n","16         factor   7.080419\n","17        driving   6.858027\n","18  extraordinary   6.858027\n","19           onto   6.858027"]},"execution_count":347,"metadata":{},"output_type":"execute_result"}],"source":["keyword_list_K2 = dispAndMakeKeyWordList(df,words, author = 2)\n","\n","keyword_list_K2 = keyword_list_K2.sort_values('keyness',ascending=False)\n","keyword_list_K2 = keyword_list_K2.reset_index(drop=True)\n","keyword_list_K2.head(20)"]},{"cell_type":"markdown","metadata":{},"source":["# 7. display the shared words in the first 20 words of each dataset\n","#Feature7"]},{"cell_type":"code","execution_count":348,"metadata":{},"outputs":[],"source":["def dispAndMakeSharedWordsFreq(df,df_ref):\n","    df = df[df['words'].isin(df_ref['words'])] #filtering with the words in df2\n","    df_ref = df_ref[df_ref['words'].isin(df['words'])] #filtering with the words in df\n","    #now the words in df and df2 are same\n","    #sort words in the alphabetical order to become the same words as the same rows\n","    df = df.sort_values('words')\n","    df_ref = df_ref.sort_values('words')\n","    #merge df2 frequency to df1 \n","    df['ref_frequency'] = list(df_ref['frequency'])\n","    df['shared_word_keyword_frequency'] = (df['frequency'] + df['ref_frequency'])\n","    return df"]},{"cell_type":"markdown","metadata":{},"source":["## Shared Words Frequency in Dataset Q and K1"]},{"cell_type":"code","execution_count":349,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>frequency</th>\n","      <th>ref_frequency</th>\n","      <th>shared_word_keyword_frequency</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>186</td>\n","      <td>78</td>\n","      <td>264</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>of</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>155</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>and</td>\n","      <td>74</td>\n","      <td>50</td>\n","      <td>124</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>to</td>\n","      <td>70</td>\n","      <td>39</td>\n","      <td>109</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>for</td>\n","      <td>55</td>\n","      <td>17</td>\n","      <td>72</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>in</td>\n","      <td>54</td>\n","      <td>42</td>\n","      <td>96</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>be</td>\n","      <td>45</td>\n","      <td>16</td>\n","      <td>61</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>or</td>\n","      <td>40</td>\n","      <td>5</td>\n","      <td>45</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>is</td>\n","      <td>31</td>\n","      <td>17</td>\n","      <td>48</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>are</td>\n","      <td>31</td>\n","      <td>4</td>\n","      <td>35</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>as</td>\n","      <td>28</td>\n","      <td>32</td>\n","      <td>60</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>time</td>\n","      <td>28</td>\n","      <td>1</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>based</td>\n","      <td>20</td>\n","      <td>6</td>\n","      <td>26</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>that</td>\n","      <td>20</td>\n","      <td>12</td>\n","      <td>32</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>system</td>\n","      <td>19</td>\n","      <td>3</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>by</td>\n","      <td>18</td>\n","      <td>13</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>such</td>\n","      <td>18</td>\n","      <td>11</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>on</td>\n","      <td>18</td>\n","      <td>15</td>\n","      <td>33</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>figure</td>\n","      <td>18</td>\n","      <td>9</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>with</td>\n","      <td>17</td>\n","      <td>9</td>\n","      <td>26</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     words  frequency  ref_frequency  shared_word_keyword_frequency\n","0      the        186             78                            264\n","1       of         89             66                            155\n","2      and         74             50                            124\n","3       to         70             39                            109\n","4      for         55             17                             72\n","5       in         54             42                             96\n","6       be         45             16                             61\n","7       or         40              5                             45\n","9       is         31             17                             48\n","10     are         31              4                             35\n","11      as         28             32                             60\n","12    time         28              1                             29\n","15   based         20              6                             26\n","16    that         20             12                             32\n","17  system         19              3                             22\n","21      by         18             13                             31\n","18    such         18             11                             29\n","20      on         18             15                             33\n","19  figure         18              9                             27\n","25    with         17              9                             26"]},"execution_count":349,"metadata":{},"output_type":"execute_result"}],"source":["#SWF = Shared Word Frequency\n","SWF_QandK1 = dispAndMakeSharedWordsFreq(wf_list_Q,wf_list_K1)\n","SWF_QandK1.sort_values('frequency', ascending=False).head(20)"]},{"cell_type":"markdown","metadata":{},"source":["## Shared Words Frequency in Dataset Q and K2"]},{"cell_type":"code","execution_count":350,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>frequency</th>\n","      <th>ref_frequency</th>\n","      <th>shared_word_keyword_frequency</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>186</td>\n","      <td>383</td>\n","      <td>569</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>of</td>\n","      <td>89</td>\n","      <td>161</td>\n","      <td>250</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>and</td>\n","      <td>74</td>\n","      <td>121</td>\n","      <td>195</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>to</td>\n","      <td>70</td>\n","      <td>128</td>\n","      <td>198</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>for</td>\n","      <td>55</td>\n","      <td>55</td>\n","      <td>110</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>in</td>\n","      <td>54</td>\n","      <td>119</td>\n","      <td>173</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>be</td>\n","      <td>45</td>\n","      <td>19</td>\n","      <td>64</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>or</td>\n","      <td>40</td>\n","      <td>10</td>\n","      <td>50</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>is</td>\n","      <td>31</td>\n","      <td>91</td>\n","      <td>122</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>are</td>\n","      <td>31</td>\n","      <td>37</td>\n","      <td>68</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>time</td>\n","      <td>28</td>\n","      <td>1</td>\n","      <td>29</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>as</td>\n","      <td>28</td>\n","      <td>36</td>\n","      <td>64</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>based</td>\n","      <td>20</td>\n","      <td>3</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>that</td>\n","      <td>20</td>\n","      <td>7</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>system</td>\n","      <td>19</td>\n","      <td>3</td>\n","      <td>22</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>figure</td>\n","      <td>18</td>\n","      <td>5</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>by</td>\n","      <td>18</td>\n","      <td>26</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>such</td>\n","      <td>18</td>\n","      <td>16</td>\n","      <td>34</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>on</td>\n","      <td>18</td>\n","      <td>26</td>\n","      <td>44</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>it</td>\n","      <td>17</td>\n","      <td>10</td>\n","      <td>27</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["     words  frequency  ref_frequency  shared_word_keyword_frequency\n","0      the        186            383                            569\n","1       of         89            161                            250\n","2      and         74            121                            195\n","3       to         70            128                            198\n","4      for         55             55                            110\n","5       in         54            119                            173\n","6       be         45             19                             64\n","7       or         40             10                             50\n","9       is         31             91                            122\n","10     are         31             37                             68\n","12    time         28              1                             29\n","11      as         28             36                             64\n","15   based         20              3                             23\n","16    that         20              7                             27\n","17  system         19              3                             22\n","19  figure         18              5                             23\n","21      by         18             26                             44\n","18    such         18             16                             34\n","20      on         18             26                             44\n","24      it         17             10                             27"]},"execution_count":350,"metadata":{},"output_type":"execute_result"}],"source":["#SWF = Shared Word Frequency\n","SWF_QandK2 = dispAndMakeSharedWordsFreq(wf_list_Q,wf_list_K2)\n","SWF_QandK2.sort_values('frequency', ascending=False).head(20)"]},{"cell_type":"markdown","metadata":{},"source":["## Display the shared keywords in the first 20 keywords of each dataset"]},{"cell_type":"code","execution_count":351,"metadata":{},"outputs":[],"source":["def dispAndMakeSharedKeyword(df,df_ref):\n","    df = df[df['words'].isin(df_ref['words'])] #filtering with the words in df2\n","    df_ref = df_ref[df_ref['words'].isin(df['words'])] #filtering with the words in df\n","    #now the words in df and df2 are same\n","    #sort words in the alphabetical order to become the same words as the same rows\n","    df = df.sort_values('words')\n","    df_ref = df_ref.sort_values('words')\n","    #merge df2 frequency to df1 \n","    df['combinedkeyness'] = list(df_ref['keyness'])\n","    \n","    return df"]},{"cell_type":"code","execution_count":352,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>keyness</th>\n","      <th>combinedkeyness</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>solutions</td>\n","      <td>8.625782</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>connected</td>\n","      <td>7.625782</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>frame</td>\n","      <td>7.362747</td>\n","      <td>5.937361</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>overcome</td>\n","      <td>7.040819</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>figure</td>\n","      <td>7.040819</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>considered</td>\n","      <td>6.625782</td>\n","      <td>7.522323</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>context</td>\n","      <td>6.362747</td>\n","      <td>4.937361</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>machine</td>\n","      <td>6.040819</td>\n","      <td>7.937361</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>models</td>\n","      <td>6.040819</td>\n","      <td>9.259289</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>influence</td>\n","      <td>6.040819</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>83</th>\n","      <td>scope</td>\n","      <td>5.455857</td>\n","      <td>6.937361</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>example</td>\n","      <td>5.455857</td>\n","      <td>4.030470</td>\n","    </tr>\n","    <tr>\n","      <th>117</th>\n","      <td>audio</td>\n","      <td>5.040819</td>\n","      <td>5.937361</td>\n","    </tr>\n","    <tr>\n","      <th>116</th>\n","      <td>commonly</td>\n","      <td>5.040819</td>\n","      <td>5.937361</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>automatically</td>\n","      <td>5.040819</td>\n","      <td>5.937361</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>relationships</td>\n","      <td>5.040819</td>\n","      <td>7.937361</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>supports</td>\n","      <td>5.040819</td>\n","      <td>5.937361</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>towards</td>\n","      <td>5.040819</td>\n","      <td>4.937361</td>\n","    </tr>\n","    <tr>\n","      <th>118</th>\n","      <td>human</td>\n","      <td>4.903315</td>\n","      <td>5.062892</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>kinds</td>\n","      <td>4.718891</td>\n","      <td>4.615433</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["             words   keyness  combinedkeyness\n","0        solutions  8.625782         6.937361\n","12       connected  7.625782         6.937361\n","13           frame  7.362747         5.937361\n","18        overcome  7.040819         6.937361\n","23          figure  7.040819         6.937361\n","31      considered  6.625782         7.522323\n","37         context  6.362747         4.937361\n","50         machine  6.040819         7.937361\n","48          models  6.040819         9.259289\n","53       influence  6.040819         6.937361\n","83           scope  5.455857         6.937361\n","84         example  5.455857         4.030470\n","117          audio  5.040819         5.937361\n","116       commonly  5.040819         5.937361\n","114  automatically  5.040819         5.937361\n","113  relationships  5.040819         7.937361\n","99        supports  5.040819         5.937361\n","98         towards  5.040819         4.937361\n","118          human  4.903315         5.062892\n","123          kinds  4.718891         4.615433"]},"execution_count":352,"metadata":{},"output_type":"execute_result"}],"source":["SK_QandK1 = dispAndMakeSharedKeyword(keyword_list_Q,keyword_list_K1)\n","SK_QandK1 = df_SK_QandK1.sort_values('keyness', ascending=False).head(20)\n","SK_QandK1.head(50)"]},{"cell_type":"code","execution_count":359,"metadata":{},"outputs":[{"data":{"text/plain":["1             cloud\n","4        configured\n","10            stage\n","23           figure\n","18         overcome\n","19      combination\n","34           device\n","32       parameters\n","66         activity\n","61     architecture\n","49        dependent\n","62          typical\n","67       addressing\n","75        locations\n","84          example\n","85       activities\n","111           shows\n","97     environments\n","95      integration\n","127         digital\n","Name: words, dtype: object"]},"execution_count":359,"metadata":{},"output_type":"execute_result"}],"source":["SK_QandK2 = dispAndMakeSharedKeyword(keyword_list_Q,keyword_list_K2)\n","SK_QandK2 = df_SK_QandK2.sort_values('keyness', ascending=False).head(20)\n","SK_QandK2.head(50)"]},{"cell_type":"markdown","metadata":{"id":"XYWb-aWPxIys"},"source":["# Prediction"]},{"cell_type":"code","execution_count":354,"metadata":{"id":"byj_PcU4dYTz"},"outputs":[],"source":["# start からend までのwordの配列を返す\n","def extract_features_words(freq_vector, words, start=0, end=20):\n","\n","    setX = set(freq_vector) # 最大値を取り出すため set を作成\n","    count = 0\n","    result = []\n","    while count<end:\n","        max_value = max(setX)\n","        max_index = freq_vector.index(max_value)\n","        max_word = words[max_index]\n","        setX.remove(max_value)\n","        ### if exclude stopwords\n","        # if max_word not in stop_words:\n","        #     if count>= start:\n","        #         result.append(max_index)\n","        #     count+=1\n","        if count>= start:\n","            result.append(max_word)\n","        count += 1\n","    return result"]},{"cell_type":"code","execution_count":355,"metadata":{},"outputs":[],"source":["result = extract_features_words(df['keyness'][0], words, 0, 20)"]},{"cell_type":"code","execution_count":356,"metadata":{},"outputs":[{"data":{"text/plain":["['solutions',\n"," 'cloud',\n"," 'configured',\n"," 'advance',\n"," 'conditions',\n"," 'frame',\n"," 'briefly',\n"," 'planning',\n"," 'user',\n"," 'deferred',\n"," 'scenarios',\n"," 'considered',\n"," 'ref',\n"," 'reminder',\n"," 'context',\n"," 'naturally',\n"," 'activity',\n"," 'location',\n"," 'concept',\n"," 'locations']"]},"execution_count":356,"metadata":{},"output_type":"execute_result"}],"source":["result"]},{"cell_type":"code","execution_count":357,"metadata":{"id":"6sUvSp9pdYT1"},"outputs":[],"source":["# start からend までのword IDの配列を返す\n","def extract_features(freq_vector, words, start=0, end=20):\n","    setX = set(freq_vector) # 最大値を取り出すため set を作成\n","    count = 0\n","    result = []\n","    while count<end:\n","        try:\n","            max_value = max(setX)\n","        except ValueError:\n","            return result\n","\n","        max_index = freq_vector.index(max_value)\n","        max_word = words[max_index]\n","\n","        setX.remove(max_value)\n","\n","        ### if exclude stopwords\n","        # if max_word not in stop_words:\n","        #     if count>= start:\n","        #         result.append(max_index)\n","        #     count+=1\n","\n","        if count>= start:\n","            result.append(max_word)\n","        count += 1\n","    return result"]},{"cell_type":"code","execution_count":360,"metadata":{},"outputs":[],"source":["#Test input\n","result = extract_features(list(SK_QandK1['words']), words, 0, 20)"]},{"cell_type":"code","execution_count":361,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1689128002510,"user":{"displayName":"米田武士","userId":"14881788265874075884"},"user_tz":-540},"id":"A63Z5oPuxIyu","outputId":"340abf3e-7bef-48cd-e839-9ff19b0ad48b"},"outputs":[{"data":{"text/plain":["['02',\n"," '01c0d27c',\n"," '00',\n"," '010129',\n"," '018',\n"," '000mmbtu',\n"," '00pm',\n"," '00cst',\n"," '023',\n"," '01',\n"," '0203',\n"," '000f749c00763c4c3b9aca0044810ab2',\n"," '005',\n"," '010206',\n"," '00am',\n"," '0072',\n"," '000',\n"," '010k',\n"," '015',\n"," '010605']"]},"execution_count":361,"metadata":{},"output_type":"execute_result"}],"source":["result"]},{"cell_type":"code","execution_count":308,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1689128002511,"user":{"displayName":"米田武士","userId":"14881788265874075884"},"user_tz":-540},"id":"u3XEgqOTdYT3","outputId":"0cbc9c22-3bbe-4637-c449-dde7ea7b1c47"},"outputs":[],"source":["# vec = reference_vectors['j..kean@enron.com']\n","# top_words = extract_features_words(vec, words=words,  start=0, end=150)\n","# print(top_words)\n"]},{"cell_type":"code","execution_count":309,"metadata":{"id":"xWhTAjQYkwOy"},"outputs":[],"source":["def get_similarity(feature_vector1,feature_vector2):\n","    return len(set(feature_vector1) & set(feature_vector2))"]},{"cell_type":"code","execution_count":310,"metadata":{"id":"BBTAic9Mdytb"},"outputs":[],"source":["INF = float('inf')\n","def predict(questioned_vector,reference_vectors):\n","    start = 0\n","    end = 20\n","    suspected = [author for author in authors]\n","    innocent_list = []\n","    while(len(suspected) > 1):\n","        Q_features = extract_features(questioned_vector, words, start, end)\n","        similarityWithQ = {}\n","        for author, reference_vector in reference_vectors.items():\n","            if author in suspected: #\n","                feature_vector = extract_features(reference_vector, words, start, end)\n","                score = get_similarity(feature_vector,Q_features)\n","                similarityWithQ[author]=score\n","\n","        # innocent_list に含まれない著者の中から1人を選ぶ\n","\n","        innocent = min(similarityWithQ, key=similarityWithQ.get)\n","        #print(innocent)\n","        # print(type(innocent))\n","        # print(f'{min(similarityWithQ, key=similarityWithQ.get)} may be innocent.')\n","        suspected.remove(innocent)\n","        # similarityWithQ[innocent] = INF\n","\n","        end += 20\n","    return suspected[0]"]},{"cell_type":"code","execution_count":311,"metadata":{"id":"vmAs7ef3xIyw"},"outputs":[],"source":["# suspected = [author for author in authors]\n","# suspected.remove('andy.zipper@enron.com')\n","# suspected"]},{"cell_type":"markdown","metadata":{"id":"BJVfCH7wy3LE"},"source":["## Check function in Train Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":313,"status":"ok","timestamp":1689128019130,"user":{"displayName":"米田武士","userId":"14881788265874075884"},"user_tz":-540},"id":"1PsLfZIkxIyx","outputId":"6a3aaede-d05d-42ba-a843-7e031f4f2869"},"outputs":[{"name":"stdout","output_type":"stream","text":["hunter.shively@enron.com\n","j..kean@enron.com\n","chris.stokley@enron.com\n","andy.zipper@enron.com\n","v.weldon@enron.com\n","bad guy : ben.jacoby@enron.com\n","--------------------\n","True author : chris.stokley@enron.com\n"]}],"source":["i = 0\n","bad_guy = predict(df['keyness'][i], reference_vectors)\n","print(f'bad guy : {bad_guy}')\n","print('-'*20)\n","print(f\"True author : {df['author'][i]}\")"]},{"cell_type":"markdown","metadata":{"id":"3IoM1rGcdYT5"},"source":["# Check function in Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1689128141907,"user":{"displayName":"米田武士","userId":"14881788265874075884"},"user_tz":-540},"id":"rUCFJ7JR4eUK","outputId":"35dbdb07-9633-4f1e-ca59-6170b2e3f626"},"outputs":[{"data":{"text/plain":["516     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","2246    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","271     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","1874    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","96      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","                              ...                        \n","1285    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","1675    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","1217    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","631     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","1048    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n","Name: keyness, Length: 531, dtype: object"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["X_keyness_test"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rHK8sTcD8RSV"},"outputs":[],"source":["all_test_data = len(X_keyness_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":341225,"status":"ok","timestamp":1689129589788,"user":{"displayName":"米田武士","userId":"14881788265874075884"},"user_tz":-540},"id":"Q3atvZGPkAP7","outputId":"87a4553b-1602-41c0-8292-f5fb7f16cd10"},"outputs":[{"name":"stdout","output_type":"stream","text":["Math rate is: 51.67216203485634 % \n"]}],"source":["match_cnt = 0\n","all_test_data = len(X_keyness_train)\n","for i in X_keyness_train.index:\n","    bad_guy = predict(df['keyness'][i], reference_vectors)\n","    if df['author'][i] == bad_guy:\n","        match_cnt = match_cnt + 1\n","\n","print(f'Math rate is: {match_cnt/all_test_data*100} % ')\n","    #print(f'bad guy : {bad_guy}')\n","    #print('-'*20)\n","    #print(f\"True author : {df['author'][i]}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t7ltZakCdYT6"},"outputs":[],"source":["# def predict(questioned_vector, reference_vectors):\n","#     suspected = [author for author in authors]\n","\n","#     comparedSize = 20\n","#     while(len(suspected) > 1):"]},{"cell_type":"markdown","metadata":{},"source":["# 没キーワード頻度取得関数等"]},{"cell_type":"code","execution_count":199,"metadata":{"id":"X6PHDHBmdYT-"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>words</th>\n","      <th>frequency</th>\n","      <th>ref_frequency</th>\n","      <th>shared_word_keyword_frequency</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>the</td>\n","      <td>383</td>\n","      <td>154</td>\n","      <td>537</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>of</td>\n","      <td>161</td>\n","      <td>65</td>\n","      <td>226</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>to</td>\n","      <td>128</td>\n","      <td>55</td>\n","      <td>183</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>and</td>\n","      <td>121</td>\n","      <td>40</td>\n","      <td>161</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>in</td>\n","      <td>119</td>\n","      <td>40</td>\n","      <td>159</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>is</td>\n","      <td>91</td>\n","      <td>12</td>\n","      <td>103</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>with</td>\n","      <td>56</td>\n","      <td>6</td>\n","      <td>62</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>for</td>\n","      <td>55</td>\n","      <td>22</td>\n","      <td>77</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>at</td>\n","      <td>50</td>\n","      <td>9</td>\n","      <td>59</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>are</td>\n","      <td>37</td>\n","      <td>5</td>\n","      <td>42</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>as</td>\n","      <td>36</td>\n","      <td>13</td>\n","      <td>49</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>up</td>\n","      <td>29</td>\n","      <td>2</td>\n","      <td>31</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>on</td>\n","      <td>26</td>\n","      <td>10</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>by</td>\n","      <td>26</td>\n","      <td>10</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>an</td>\n","      <td>24</td>\n","      <td>6</td>\n","      <td>30</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>operating</td>\n","      <td>22</td>\n","      <td>1</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>100</td>\n","      <td>22</td>\n","      <td>1</td>\n","      <td>23</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>be</td>\n","      <td>19</td>\n","      <td>21</td>\n","      <td>40</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>after</td>\n","      <td>17</td>\n","      <td>4</td>\n","      <td>21</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>which</td>\n","      <td>17</td>\n","      <td>13</td>\n","      <td>30</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        words  frequency  ref_frequency  shared_word_keyword_frequency\n","0         the        383            154                            537\n","1          of        161             65                            226\n","2          to        128             55                            183\n","3         and        121             40                            161\n","4          in        119             40                            159\n","5          is         91             12                            103\n","8        with         56              6                             62\n","9         for         55             22                             77\n","11         at         50              9                             59\n","15        are         37              5                             42\n","17         as         36             13                             49\n","19         up         29              2                             31\n","23         on         26             10                             36\n","22         by         26             10                             36\n","25         an         24              6                             30\n","27  operating         22              1                             23\n","26        100         22              1                             23\n","33         be         19             21                             40\n","35      after         17              4                             21\n","37      which         17             13                             30"]},"execution_count":199,"metadata":{},"output_type":"execute_result"}],"source":["# def dispAndMakeSharedKeywordFreq(df,df_ref):\n","#     df = df[df['words'].isin(df_ref['words'])] #filtering with the words in df2\n","#     df_ref = df_ref[df_ref['words'].isin(df['words'])] #filtering with the words in df\n","#     #now the words in df and df2 are same\n","#     #sort words in the alphabetical order to become the same words as the same rows\n","#     df = df.sort_values('words')\n","#     df_ref = df_ref.sort_values('words')\n","#     #merge df2 frequency to df1 \n","#     df['ref_frequency'] = list(df_ref['frequency'])\n","#     df['shared_word_keyword_frequency'] = (df['frequency'] + df['ref_frequency'])\n","#     return df\n","## Keyword Frequency in Dataset Q and Ref\n","#KF = Keyword Frequency\n","# KF_QandRef = dispAndMakeSharedKeywordFreq(wf_list_Q,wf_list_ref)\n","# KF_QandRef.sort_values('frequency', ascending=False).head(20)\n","# ## Keyword Frequency in Dataset K1 and Ref\n","# #KF = Shared Keyword Frequency\n","# KF_QandRef = dispAndMakeSharedKeywordFreq(wf_list_K1,wf_list_ref)\n","# KF_QandRef.sort_values('frequency', ascending=False).head(20)\n","# ## Keyword Frequency in Dataset K2 and Ref\n","# #KF = Shared Keyword Frequency\n","# KF_QandRef = dispAndMakeSharedKeywordFreq(wf_list_K2,wf_list_ref)\n","# KF_QandRef.sort_values('frequency', ascending=False).head(20)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import nltk\n","# from nltk.corpus import stopwords\n","\n","# nltk.download('stopwords')\n","# stop_words = stopwords.words('english')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# #確認用\n","# i = 22\n","# msg = df['body'][i]\n","# max_value = max(keyness_mat[i])\n","# max_idx = keyness_mat[i].index(max_value)\n","# print(words[max_idx])\n","\n","# print(msg)\n","# #print(df['author'][i])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from sklearn.model_selection import train_test_split\n","# X_keyness_train, X_keyness_test, Y_keyness_train, Y_keyness_test = train_test_split(df['keyness'],df['author'],test_size=0.2,shuffle=True)\n","# X_tf_train, X_tf_test, Y_tf_train, Y_tf_test = train_test_split(df['tf'],df['author'],test_size=0.2,shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # How many author?\n","# authors = set(Y_keyness_test)\n","# authors_list = [author for author in authors]"]},{"cell_type":"markdown","metadata":{},"source":["# Create Reference_vectors\n","size: 著者の数\n","\n","Train データから作る"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # df_X = pd.DataFrame(X_tf_train.values.tolist())\n","# # df_Y = pd.DataFrame(Y_tf_train.values.tolist())\n","\n","\n","# df_train = pd.concat((X_keyness_train, Y_keyness_train.rename('author')), axis=1)\n","# #\n","# reference_vectors = {}\n","# for author in authors:\n","\n","#     df_author = df_train.groupby('author').get_group(author)\n","\n","#     matrix = []\n","#     for row in df_author['keyness']:\n","#         matrix.append(row)\n","\n","#     np_matrix = np.array(matrix)\n","\n","#     mean_vector = np_matrix.mean(axis=0)\n","#     reference_vectors[author] = mean_vector.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["hunter.shively@enron.com: hunter\n","j..kean@enron.com: attached\n","chris.stokley@enron.com: chris\n","v.weldon@enron.com: charlie\n","ben.jacoby@enron.com: ben\n","andy.zipper@enron.com: andy\n"]}],"source":["# for author, ref_vec in reference_vectors.items():\n","#     max_value = max(ref_vec)\n","#     max_idx =ref_vec.index(max_value)\n","#     print(f'{author}: {words[max_idx]}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["{'andy.zipper@enron.com',\n"," 'ben.jacoby@enron.com',\n"," 'chris.stokley@enron.com',\n"," 'hunter.shively@enron.com',\n"," 'j..kean@enron.com',\n"," 'v.weldon@enron.com'}"]},"metadata":{},"output_type":"display_data"}],"source":["# authors"]},{"cell_type":"markdown","metadata":{"id":"qsTpIbg_dYT_"},"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"expsystem","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
